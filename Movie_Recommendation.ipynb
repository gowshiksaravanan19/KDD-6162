{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hr7SGYEq69wv"
   },
   "source": [
    "# ITCS 6162: Data Mining - Programming Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_idzFtE7M_9"
   },
   "source": [
    "**In this assignment, you will explore data analysis, recommendation algorithms, and graph-based techniques using the MovieLens dataset. Your tasks will range from basic data exploration to advanced recommendation models, including:**\n",
    "- Data manipulation with pandas\n",
    "- User-item collaborative filtering\n",
    "- Similarity-based recommendation models\n",
    "- A Pixie-inspired Graph-based recommendation using adjacency lists with weighted random walks (without using NetworkX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZxjOF_l79zc"
   },
   "source": [
    "#### **Dataset Files:**\n",
    "- **`u.data`**: User-movie ratings (`user_id  movie_id  rating  timestamp`)\n",
    "- **`u.item`**: Movie metadata (`movie_id | title | release date | IMDB_website`)\n",
    "- **`u.user`**: User demographics (`user_id | age | gender | occupation | zip_code`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytr6isc2F9g6"
   },
   "source": [
    "## **Part 1: Exploring and Cleaning Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87kIrhTC9Ba1"
   },
   "source": [
    "### Inspecting the Dataset Format\n",
    "\n",
    "The dataset is not in a traditional CSV format. To examine its structure, use the following shell command to display the first 10 lines of the file:\n",
    "\n",
    "```sh\n",
    "!head <file_name>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjOtbBWM9xWv"
   },
   "source": [
    "**In the cells given below. Write the code to read the files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "XOoSaKsq68nD"
   },
   "outputs": [],
   "source": [
    "# Cell to have all the imports for the project\n",
    "import pandas as pd\n",
    "import numpy as np   # For numerical computations\n",
    "from sklearn.metrics.pairwise import cosine_similarity # For computing user similarity\n",
    "import random  # For random walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\t242\t3\t881250949\n",
      "186\t302\t3\t891717742\n",
      "22\t377\t1\t878887116\n",
      "244\t51\t2\t880606923\n",
      "166\t346\t1\t886397596\n",
      "298\t474\t4\t884182806\n",
      "115\t265\t2\t881171488\n",
      "253\t465\t5\t891628467\n",
      "305\t451\t3\t886324817\n",
      "6\t86\t3\t883603013\n"
     ]
    }
   ],
   "source": [
    "# Displaying first 10 rows of u.data dataset\n",
    "!head u.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "dckMko0o9t-D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
      "2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\n",
      "3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\n",
      "4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
      "5|Copycat (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Copycat%20(1995)|0|0|0|0|0|0|1|0|1|0|0|0|0|0|0|0|1|0|0\n",
      "6|Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)|01-Jan-1995||http://us.imdb.com/Title?Yao+a+yao+yao+dao+waipo+qiao+(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
      "7|Twelve Monkeys (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Twelve%20Monkeys%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|1|0|0|0\n",
      "8|Babe (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Babe%20(1995)|0|0|0|0|1|1|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
      "9|Dead Man Walking (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Dead%20Man%20Walking%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
      "10|Richard III (1995)|22-Jan-1996||http://us.imdb.com/M/title-exact?Richard%20III%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|1|0\n"
     ]
    }
   ],
   "source": [
    "# Displaying first 10 rows of u.item dataset\n",
    "!head u.item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "R7kBwpsi-WKB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|24|M|technician|85711\n",
      "2|53|F|other|94043\n",
      "3|23|M|writer|32067\n",
      "4|24|M|technician|43537\n",
      "5|33|F|other|15213\n",
      "6|42|M|executive|98101\n",
      "7|57|M|administrator|91344\n",
      "8|36|M|administrator|05201\n",
      "9|29|M|student|01002\n",
      "10|53|M|lawyer|90703\n"
     ]
    }
   ],
   "source": [
    "# Displaying first 10 rows of u.user dataset\n",
    "!head u.user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnryIHO7-db3"
   },
   "source": [
    "#### Loading the Dataset with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jwmza7riBj30"
   },
   "source": [
    "Use **pandas** to load the dataset into a DataFrame for analysis. Follow these steps:  \n",
    "\n",
    "1. Import the necessary library: `pandas`.  \n",
    "2. Use `pd.read_csv()` (or an appropriate function) to read the dataset file.  \n",
    "3. Ensure the dataset is loaded with the correct delimiter (e.g., `','`, `'\\t'`,`'|'` , or another separator if needed).  \n",
    "4. Select and display the first few rows using `.head()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPEDYYGOBOSD"
   },
   "source": [
    "Ensure that:  \n",
    "\n",
    "- The `ratings` dataset is read from `\"u.data\"` using tab (`'\\t'`) as a separator and column names (`\"user_id\"`, `\"movie_id\"`, `\"rating\"` and `\"timestamp\"`).  \n",
    "- The `movies` dataset is read from `\"u.item\"` using `'|'` as a separator, use columns (`0`, `1`, `2`), encoding (`\"latin-1\"`) and name the columns (`movie_id`, `title`, and `release_date`).  \n",
    "- The `users` dataset is read from `\"u.user\"` using `'|'` as a separator, use columns (`0`, `1`, `2`, `3`) and name the columns (`user_id`, `age`, `gender`, and `occupation`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "Go-Y-Ofy-ZTk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0      196       242       3  881250949\n",
       "1      186       302       3  891717742\n",
       "2       22       377       1  878887116\n",
       "3      244        51       2  880606923\n",
       "4      166       346       1  886397596"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratings\n",
    "# Converting u.data into dataframe named ratings\n",
    "ratings_column = ['user_id', 'movie_id', 'rating', 'timestamp'] # Defining columns for the data frame\n",
    "ratings = pd.read_csv(\"u.data\", sep=\"\\t\", names=ratings_column, header=None) # As column names are explictly provided, no need to treat first row as column name and header=None\n",
    "ratings.head() #Displaying first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "zM8IJGh-CLN5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id              title release_date\n",
       "0         1   Toy Story (1995)  01-Jan-1995\n",
       "1         2   GoldenEye (1995)  01-Jan-1995\n",
       "2         3  Four Rooms (1995)  01-Jan-1995\n",
       "3         4  Get Shorty (1995)  01-Jan-1995\n",
       "4         5     Copycat (1995)  01-Jan-1995"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movies\n",
    "movies_column = ['movie_id', 'title', 'release_date'] # Defining columns for the data frame\n",
    "# As column names are explictly provided, no need to treat first row as column name and header=None. As provided in instruction notes only columns 0, 1 and 2 are considered and encoding is done\n",
    "movies = pd.read_csv(\"u.item\", sep=\"|\", encoding='latin-1', usecols=[0, 1, 2], names=movies_column, header=None)\n",
    "movies.head() #Displaying first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "hsekVjevCNKj"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age gender  occupation\n",
       "0        1   24      M  technician\n",
       "1        2   53      F       other\n",
       "2        3   23      M      writer\n",
       "3        4   24      M  technician\n",
       "4        5   33      F       other"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# users\n",
    "users_column = ['user_id', 'age', 'gender', 'occupation']  # Defining columns for the data frame\n",
    "# As column names are explictly provided, no need to treat first row as column name and header=None. As provided in instruction notes only columns 0, 1 and 2 are considered.\n",
    "users = pd.read_csv(\"u.user\", sep=\"|\", usecols=[0, 1, 2, 3], names=users_column, header=None)\n",
    "users.head() #Displaying first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jE5OHLqt7xeq"
   },
   "source": [
    "**Note:** As a **Bonus** task save the `ratings`, `movies` and `users` dataframe created into a `.csv` file format. <br>\n",
    "**Hint:** Use the `to_csv()` function in pandas to save these DataFrames as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "Chyv3c4n8wVC"
   },
   "outputs": [],
   "source": [
    "# ratings\n",
    "#Saving ratings dataframe as .csv and gets saved to the same location where .ipynb is located\n",
    "ratings.to_csv(\"ratings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "Gl7zVV3y8wKU"
   },
   "outputs": [],
   "source": [
    "# movies\n",
    "#Saving movies dataframe as .csv and gets saved to the same location where .ipynb is located\n",
    "movies.to_csv(\"movies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "0YwVuebp8u46"
   },
   "outputs": [],
   "source": [
    "# users\n",
    "#Saving users dataframe as .csv and gets saved to the same location where .ipynb is located\n",
    "users.to_csv(\"users.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3S1y82cCYxx"
   },
   "source": [
    "**Display the first 10 rows of each file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "x5ZOXTqnCPgw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  timestamp\n",
      "0      196       242       3  881250949\n",
      "1      186       302       3  891717742\n",
      "2       22       377       1  878887116\n",
      "3      244        51       2  880606923\n",
      "4      166       346       1  886397596\n",
      "5      298       474       4  884182806\n",
      "6      115       265       2  881171488\n",
      "7      253       465       5  891628467\n",
      "8      305       451       3  886324817\n",
      "9        6        86       3  883603013\n"
     ]
    }
   ],
   "source": [
    "# ratings\n",
    "# Load the CSV file\n",
    "ratings_data = pd.read_csv(\"ratings.csv\")\n",
    "\n",
    "# Display the first 10 rows\n",
    "print(ratings_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "AzuqiRkrCdfZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movie_id                                              title release_date\n",
      "0         1                                   Toy Story (1995)  01-Jan-1995\n",
      "1         2                                   GoldenEye (1995)  01-Jan-1995\n",
      "2         3                                  Four Rooms (1995)  01-Jan-1995\n",
      "3         4                                  Get Shorty (1995)  01-Jan-1995\n",
      "4         5                                     Copycat (1995)  01-Jan-1995\n",
      "5         6  Shanghai Triad (Yao a yao yao dao waipo qiao) ...  01-Jan-1995\n",
      "6         7                              Twelve Monkeys (1995)  01-Jan-1995\n",
      "7         8                                        Babe (1995)  01-Jan-1995\n",
      "8         9                            Dead Man Walking (1995)  01-Jan-1995\n",
      "9        10                                 Richard III (1995)  22-Jan-1996\n"
     ]
    }
   ],
   "source": [
    "# movies\n",
    "# Load the CSV file\n",
    "movies_data = pd.read_csv(\"movies.csv\")\n",
    "\n",
    "# Display the first 10 rows\n",
    "print(movies_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "FE9hcM9mCewe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  age gender     occupation\n",
      "0        1   24      M     technician\n",
      "1        2   53      F          other\n",
      "2        3   23      M         writer\n",
      "3        4   24      M     technician\n",
      "4        5   33      F          other\n",
      "5        6   42      M      executive\n",
      "6        7   57      M  administrator\n",
      "7        8   36      M  administrator\n",
      "8        9   29      M        student\n",
      "9       10   53      M         lawyer\n"
     ]
    }
   ],
   "source": [
    "# users\n",
    "# Load the CSV file\n",
    "users_data = pd.read_csv(\"users.csv\")\n",
    "\n",
    "# Display the first 10 rows\n",
    "print(users_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i38iDIz-DiVj"
   },
   "source": [
    "### Data Cleaning and Exploration with Pandas  \n",
    "\n",
    "After loading the dataset, it’s important to clean and explore the data to ensure consistency and accuracy. Below are key **pandas** functions for cleaning and understanding the dataset.\n",
    "\n",
    "#### 1. Handle Missing Values  \n",
    "- `df.dropna()` – Removes rows with missing values.  \n",
    "- `df.fillna(value)` – Fills missing values with a specified value.  \n",
    "\n",
    "#### 2. Remove Duplicates  \n",
    "- `df.drop_duplicates()` – Drops duplicate rows from the dataset.  \n",
    "\n",
    "#### 3. Handle Incorrect Data Types  \n",
    "- `df.astype(dtype)` – Converts columns to the appropriate data type.  \n",
    "\n",
    "#### 4. Filter Outliers (if applicable)  \n",
    "- `df[df['column_name'] > threshold]` – Filters rows based on a condition.  \n",
    "\n",
    "#### 5. Rename Columns (if needed)  \n",
    "- `df.rename(columns={'old_name': 'new_name'})` – Renames columns for clarity.  \n",
    "\n",
    "#### 6. Reset Index  \n",
    "- `df.reset_index(drop=True, inplace=True)` – Resets the index after cleaning.  \n",
    "\n",
    "### Data Exploration Functions  \n",
    "\n",
    "To better understand the dataset, use these **pandas** functions:  \n",
    "\n",
    "- `df.shape` – Returns the number of rows and columns in the dataset.  \n",
    "- `df.nunique()` – Displays the number of unique values in each column.  \n",
    "- `df['column_name'].unique()` – Returns unique values in a specific column.  \n",
    "\n",
    "**Example Usage in Pandas:**  \n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"your_file.csv\")\n",
    "\n",
    "# Drop missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Remove duplicate rows\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "\n",
    "# Convert 'timestamp' column to datetime format\n",
    "df_cleaned['timestamp'] = pd.to_datetime(df_cleaned['timestamp'])\n",
    "\n",
    "# Display dataset shape\n",
    "print(\"Dataset shape:\", df_cleaned.shape)\n",
    "\n",
    "# Display number of unique values in each column\n",
    "print(\"Unique values per column:\\n\", df_cleaned.nunique())\n",
    "\n",
    "# Display unique movie IDs\n",
    "print(\"Unique movie IDs:\", df_cleaned['movie_id'].unique()[:10])  # Show first 10 unique movie IDs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cwmLON4EItA"
   },
   "source": [
    "**Note:** The functions mentioned above are some of the widely used **pandas** functions for data cleaning and exploration. However, it is not necessary that all of these functions will be required in the exercises below. Use them as needed based on the dataset and the specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tn0bLOSACxMP"
   },
   "source": [
    "**Convert Timestamps into Readable dates.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "9MwnDxeeCf8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating           timestamp\n",
      "0      196       242       3 1997-12-04 15:55:49\n",
      "1      186       302       3 1998-04-04 19:22:22\n",
      "2       22       377       1 1997-11-07 07:18:36\n",
      "3      244        51       2 1997-11-27 05:02:03\n",
      "4      166       346       1 1998-02-02 05:33:16\n",
      "5      298       474       4 1998-01-07 14:20:06\n",
      "6      115       265       2 1997-12-03 17:51:28\n",
      "7      253       465       5 1998-04-03 18:34:27\n",
      "8      305       451       3 1998-02-01 09:20:17\n",
      "9        6        86       3 1997-12-31 21:16:53\n"
     ]
    }
   ],
   "source": [
    "# ratings\n",
    "ratings_data['timestamp'] = pd.to_datetime(ratings_data['timestamp'], unit='s') #As the timestamp is in seconds unit is given as 's'\n",
    "print(ratings_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKJB0a9CE0Z4"
   },
   "source": [
    "**Check for Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "iYf4NM47DL7q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Empty DataFrame\n",
      "Columns: [user_id, movie_id, rating, timestamp]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# ratings\n",
    "print(ratings_data.isnull().values.any())\n",
    "rating_missing_rows = ratings_data[ratings_data.isnull().any(axis=1)]\n",
    "print(rating_missing_rows)\n",
    "# There is no missing value or cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "hgM78fNaFH2q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "     movie_id    title release_date\n",
      "266       267  unknown          NaN\n"
     ]
    }
   ],
   "source": [
    "# movies\n",
    "print(movies_data.isnull().values.any())\n",
    "movie_missing_rows = movies_data[movies_data.isnull().any(axis=1)]\n",
    "print(movie_missing_rows)\n",
    "# Only for movie id 267, release_date is not available but it is trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "jE8J_cajFA5n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Empty DataFrame\n",
      "Columns: [user_id, age, gender, occupation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# users\n",
    "print(users.isnull().values.any())\n",
    "user_missing_rows = users_data[users_data.isnull().any(axis=1)]\n",
    "print(user_missing_rows)\n",
    "# There is no missing value or cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings:\n",
      " Empty DataFrame\n",
      "Columns: [user_id, movie_id, rating, timestamp]\n",
      "Index: []\n",
      "movies:\n",
      " Empty DataFrame\n",
      "Columns: [movie_id, title, release_date]\n",
      "Index: []\n",
      "users:\n",
      " Empty DataFrame\n",
      "Columns: [user_id, age, gender, occupation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Check for duplicate values\n",
    "ratings_duplicates = ratings_data[ratings_data.duplicated(subset=['user_id', 'movie_id'])]\n",
    "movies_duplicates = movies_data[movies_data['movie_id'].duplicated()]\n",
    "users_duplicates = users_data[users_data['user_id'].duplicated()]\n",
    "print(\"ratings:\\n\", ratings_duplicates)\n",
    "print(\"movies:\\n\", movies_duplicates)\n",
    "print(\"users:\\n\", users_duplicates)\n",
    "#No user or movie is duplicated and no user-movie is rated duplicately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WviFe7iFRoQ"
   },
   "source": [
    "**Print the total number of users, movies, and ratings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "eR_QgS9aFTPb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Users: 943\n",
      "Total Movies: 1682\n",
      "Total Ratings: 100000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Users: { users_data['user_id'].nunique() }\") # no.of unique users\n",
    "print(f\"Total Movies: { movies_data['movie_id'].nunique() }\") # no.of unique movies\n",
    "print(f\"Total Ratings: { len(ratings_data) }\") # As no user_movie pair is duplicated count the number of total rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjxACjUgFwsk"
   },
   "source": [
    "## **Part 2: Collaborative Filtering-Based Recommendation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyeSaLpRGYuC"
   },
   "source": [
    "### **Create a User-Item Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tKsv-7XHRq2"
   },
   "source": [
    "#### Instructions for Creating a User-Movie Rating Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLayr0YbH4tB"
   },
   "source": [
    "In this exercise, you will create a user-movie rating matrix using **pandas**. This matrix will represent the ratings that users have given to different movies.\n",
    "\n",
    "1. **Dataset Overview**:  \n",
    "   The dataset has already been loaded. It includes the following key columns:\n",
    "   - `user_id`: The ID of the user.\n",
    "   - `movie_id`: The ID of the movie.\n",
    "   - `ratings`: The rating the user gave to the movie.\n",
    "\n",
    "2. **Create the User-Movie Rating Matrix**:  \n",
    "   Use the **`pivot()`** function in **pandas** to reshape the data. Your goal is to create a matrix where:\n",
    "   - Each **row** represents a **user**.\n",
    "   - Each **column** represents a **movie**.\n",
    "   - Each **cell** contains the **rating** that the user has given to the movie.\n",
    "\n",
    "   Specify the following parameters for the `pivot()` function:\n",
    "   - **`index`**: The `user_id` column (this will define the rows).\n",
    "   - **`columns`**: The `movie_id` column (this will define the columns).\n",
    "   - **`values`**: The `rating` column (this will fill the matrix with ratings).\n",
    "\n",
    "3. **Inspect the Matrix**:  \n",
    "   After creating the matrix, examine the first few rows of the resulting matrix to ensure it has been constructed correctly.\n",
    "\n",
    "4. **Handle Missing Values**:  \n",
    "   It's likely that some users have not rated every movie, resulting in `NaN` values in the matrix. You will need to handle these missing values. Consider the following options:\n",
    "   - **Fill with 0**: If you wish to represent missing ratings as zeros (indicating no rating).\n",
    "   - **Fill with the average rating**: Alternatively, replace missing values with the average rating for each movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_cdPXYeaD-l"
   },
   "source": [
    "**Create the user-movie rating matrix using the `pivot()` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "Ie858yKEUSfc"
   },
   "outputs": [],
   "source": [
    "user_movie_matrix = ratings_data.pivot(index='user_id', columns='movie_id', values='rating') #Formation of user-movie matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyb3h9FmaVGH"
   },
   "source": [
    "**Display the matrix to verify the transformation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "16abaOrXabN_"
   },
   "outputs": [],
   "source": [
    "user_movie_matrix_1 = user_movie_matrix.fillna(0) # Replace Nan with 0\n",
    "user_similarity = cosine_similarity(user_movie_matrix_1) # Find similarity between users using cosine similarity\n",
    "user_user_sim = pd.DataFrame(user_similarity, index=user_movie_matrix_1.index, columns=user_movie_matrix_1.index) # Convert into 2d similarity dataframe with both rows and columns as users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOXp00QSbtHk"
   },
   "source": [
    "### **User-Based Collaborative Filtering Recommender System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwKBZk5Sc7YA"
   },
   "source": [
    "#### **Objective**\n",
    "In this task, you will implement a **user-based collaborative filtering** movie recommendation system using the **Movie dataset**. The goal is to recommend movies to a user based on the preferences of similar users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZf-Nu2rdPHR"
   },
   "source": [
    "##### **Step 1: Import Required Libraries**\n",
    "Before starting, ensure you have the necessary libraries installed. Use the following imports:\n",
    "\n",
    "```python\n",
    "import pandas as pd  # For handling data\n",
    "import numpy as np   # For numerical computations\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # For computing user similarity\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzJNshMbdwyR"
   },
   "source": [
    "##### **Step 2: Compute User-User Similarity**\n",
    "- We will use **cosine similarity** to measure how similar each pair of users is based on their movie ratings.\n",
    "- Since `cosine_similarity` does not handle missing values (NaN), replace them with `0` before computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkO_XtPqd4Sw"
   },
   "source": [
    "##### **Instructions:**\n",
    "1. Fill missing values with `0` using `.fillna(0)`.\n",
    "2. Compute similarity using `cosine_similarity()`.\n",
    "3. Convert the result into a **Pandas DataFrame**, with users as both row and column labels.\n",
    "\n",
    "##### **Hint:**  \n",
    "You can achieve this using the following approach:\n",
    "\n",
    "```python\n",
    "user_similarity = cosine_similarity(user_movie_matrix.fillna(0))\n",
    "user_sim_df = pd.DataFrame(user_similarity, index=user_movie_matrix.index, columns=user_movie_matrix.index)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtmluaSGeBE-"
   },
   "source": [
    "##### **Step 3: Implement the Recommendation Function**\n",
    "Now, implement the function `recommend_movies_for_user(user_id, num=5)` to recommend movies for a given user.\n",
    "\n",
    "##### **Function Inputs:**\n",
    "- `user_id`: The target user for whom we need recommendations.\n",
    "- `num`: The number of movies to recommend (default is 5).\n",
    "\n",
    "##### **Function Steps:**\n",
    "1. Find **similar users**:\n",
    "   - Retrieve the similarity scores for the given `user_id`.\n",
    "   - Sort them in **descending** order (highest similarity first).\n",
    "   - Exclude the user themselves.\n",
    "   \n",
    "2. Get the **movie ratings** from these similar users.\n",
    "\n",
    "3. Compute the **average rating** for each movie based on these users' preferences.\n",
    "\n",
    "4. Sort the movies in **descending order** based on the computed average ratings.\n",
    "\n",
    "5. Retrieve the **top `num` recommended movies**.\n",
    "\n",
    "6. Map **movie IDs** to their **titles** using the `movies` DataFrame.\n",
    "\n",
    "7. Return the results as a **Pandas DataFrame** with rankings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgO0zd8LeGJ_"
   },
   "source": [
    "##### **Step 4: Return the Final Recommendation List**\n",
    "Your function should return a **DataFrame** structured as follows:\n",
    "\n",
    "| Ranking | Movie Name |\n",
    "|---------|-----------|\n",
    "| 1       | Movie A   |\n",
    "| 2       | Movie B   |\n",
    "| 3       | Movie C   |\n",
    "| 4       | Movie D   |\n",
    "| 5       | Movie E   |\n",
    "\n",
    "##### **Hint:** Your final DataFrame should be created like this:\n",
    "```python\n",
    "result_df = pd.DataFrame({\n",
    "    'Ranking': range(1, num+1),\n",
    "    'Movie Name': movie_names     \n",
    "})\n",
    "result_df.set_index('Ranking', inplace=True)\n",
    "```\n",
    "\n",
    "#### **Example: User-Based Collaborative Filtering**\n",
    "```python\n",
    "recommend_movies_for_user(10, num = 5)\n",
    "```\n",
    "**Output:**\n",
    "```\n",
    "| Ranking | Movie Name                     |\n",
    "|---------|--------------------------------|\n",
    "| 1       | In the Company of Men (1997)   |\n",
    "| 2       | Misérables, Les (1995)         |\n",
    "| 3       | Thin Blue Line, The (1988)     |\n",
    "| 4       | Braindead (1992)               |\n",
    "| 5       | Boys, Les (1997)               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "rbENugJ5cUpo"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the user id :  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Ranking | Movie Name                       |\n",
      "|---------|----------------------------------|\n",
      "| 1       | Star Wars (1977)                 |\n",
      "| 2       | Return of the Jedi (1983)        |\n",
      "| 3       | Fargo (1996)                     |\n",
      "| 4       | Raiders of the Lost Ark (1981)   |\n",
      "| 5       | Silence of the Lambs, The (1991) |\n"
     ]
    }
   ],
   "source": [
    "# Code the function here\n",
    "user_id = int(input(\"Enter the user id : \")) # Get the user_id from user\n",
    "num = 5 # No.of recommendations (As default is 5)\n",
    "if user_id < 1 or user_id > len(user_user_sim): # Check if user_id is between 1 and 943 inclusive\n",
    "    print(\"Invalid Input \\nAccepted values are: \\nuser_id=[1,943]\") #Throw error\n",
    "else: # If user_id is valid\n",
    "    non_zero_mask = user_movie_matrix != 0 # Create a mask where ratings are non-zero. True when rating is present and False when movie is not rated\n",
    "    similarity_row = user_user_sim.loc[user_id] # Get the row of the inputted user_id\n",
    "    similarity_row[user_id] = 0 # Exclude the user's own similarity\n",
    "    masked_similarities = non_zero_mask.mul(similarity_row, axis=0) # Keeps similarity scores only for users who rated a given movie. Zeros out the similarity if a user didn’t rate that movie.\n",
    "    # Multiply the above non_zero_mask with the user_movie matrix A matrix where each rating position is replaced by the similarity of that user, only if the user rated that movie. Otherwise, it remains 0.\n",
    "    weighted_sum = user_movie_matrix.mul(masked_similarities, axis=0).sum(axis=0)\n",
    "    sim_sum = masked_similarities.sum(axis=0) # Compute sum of similarities only for users who rated\n",
    "    predicted_ratings = (weighted_sum / sim_sum).fillna(0) # Avoid division by zero (fill NaN with 0)\n",
    "    top_movie_ids = predicted_ratings.sort_values(ascending=False).head(num).index # Get top 5 movie IDs from predicted ratings\n",
    "    movie_id_to_title = movies.set_index('movie_id')['title'] # Map movie_id to title from the movies DataFrame\n",
    "    top_movie_titles = top_movie_ids.map(movie_id_to_title)\n",
    "    # Do the below to print in the required format\n",
    "    # Convert to Series (if needed) for apply\n",
    "    top_movie_titles_series = pd.Series(top_movie_titles)\n",
    "    # Calculate max width for alignment\n",
    "    title_width = max(top_movie_titles_series.apply(len).max(), len(\"Movie Name\"))\n",
    "    # Print table header\n",
    "    print(f\"| Ranking | {'Movie Name'.ljust(title_width)} |\")\n",
    "    print(f\"|{'-' * 9}|{'-' * (title_width + 2)}|\")\n",
    "    # Print each movie with ranking\n",
    "    for rank, title in enumerate(top_movie_titles, start=1):\n",
    "        print(f\"| {str(rank).ljust(7)} | {title.ljust(title_width)} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIN3XqC0eUAu"
   },
   "source": [
    "### **Item-Based Collaborative Filtering Recommender System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytqWK-4ze2aA"
   },
   "source": [
    "#### **Objective**\n",
    "In this task, you will implement an **item-based collaborative filtering** recommendation system using the **Movie dataset**. The goal is to recommend movies similar to a given movie based on user rating patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0-HuDvffY57"
   },
   "source": [
    "#### **Step 1: Import Required Libraries**\n",
    "Although we have done this part already in the previous task but just to emphasize the importance reiterrating this part.\n",
    "\n",
    "Before starting, ensure you have the necessary libraries installed. Use the following imports:\n",
    "\n",
    "```python\n",
    "import pandas as pd  # For handling data\n",
    "import numpy as np   # For numerical computations\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # For computing item similarity\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9oy7pojf19r"
   },
   "source": [
    "#### **Step 2: Compute Item-Item Similarity**\n",
    "- We will use **cosine similarity** to measure how similar each pair of movies is based on their user ratings.\n",
    "- Since `cosine_similarity` does not handle missing values (NaN), replace them with `0` before computation.\n",
    "- Unlike user-based filtering, we need to **transpose** (`.T`) the `user_movie_matrix` because we want similarity between movies (columns) instead of users (rows).\n",
    "\n",
    "##### **Instructions:**\n",
    "1. Transpose the user-movie matrix using `.T` to make movies the rows.\n",
    "2. Fill missing values with `0` using `.fillna(0)`.\n",
    "3. Compute similarity using `cosine_similarity()`.\n",
    "4. Convert the result into a **Pandas DataFrame**, with movies as both row and column labels.\n",
    "\n",
    "##### **Hint:**  \n",
    "You can achieve this using the following approach:\n",
    "\n",
    "```python\n",
    "item_similarity = cosine_similarity(user_movie_matrix.T.fillna(0))\n",
    "item_sim_df = pd.DataFrame(item_similarity, index=user_movie_matrix.columns, columns=user_movie_matrix.columns)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8k80idUgDWW"
   },
   "source": [
    "#### **Step 3: Implement the Recommendation Function**\n",
    "Now, implement the function `recommend_movies(movie_name, num=5)` to recommend movies similar to a given movie.\n",
    "\n",
    "##### **Function Inputs:**\n",
    "- `movie_name`: The target movie for which we need recommendations.\n",
    "- `num`: The number of similar movies to recommend (default is 5).\n",
    "\n",
    "##### **Function Steps:**\n",
    "1. Find the **movie_id** corresponding to the given `movie_name` in the `movies` DataFrame.\n",
    "2. If the movie is not found, return an appropriate message.\n",
    "3. Extract the **similarity scores** for this movie from `item_sim_df`.\n",
    "4. Sort the movies in **descending order** based on similarity (excluding the movie itself).\n",
    "5. Retrieve the **top `num` similar movies**.\n",
    "6. Map **movie IDs** to their **titles** using the `movies` DataFrame.\n",
    "7. Return the results as a **Pandas DataFrame** with rankings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNRZQWQkgLPf"
   },
   "source": [
    "#### **Step 4: Return the Final Recommendation List**\n",
    "Your function should return a **DataFrame** structured as follows:\n",
    "\n",
    "| Ranking | Movie Name |\n",
    "|---------|-----------|\n",
    "| 1       | Movie A   |\n",
    "| 2       | Movie B   |\n",
    "| 3       | Movie C   |\n",
    "| 4       | Movie D   |\n",
    "| 5       | Movie E   |\n",
    "\n",
    "##### **Hint:** Your final DataFrame should be created like this:\n",
    "```python\n",
    "result_df = pd.DataFrame({\n",
    "    'ranking': range(1, num+1),\n",
    "    'movie_name': movie_names\n",
    "})\n",
    "result_df.set_index('ranking', inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-EEF0Q1gd9N"
   },
   "source": [
    "#### **Example: Item-Based Collaborative Filtering**\n",
    "```python\n",
    "recommend_movies(\"Jurassic Park (1993)\", num=5)\n",
    "```\n",
    "**Output:**\n",
    "```\n",
    "| Ranking | Movie Name                               |\n",
    "|---------|------------------------------------------|\n",
    "| 1       | Top Gun (1986)                           |\n",
    "| 2       | Empire Strikes Back, The (1980)          |\n",
    "| 3       | Raiders of the Lost Ark (1981)           |\n",
    "| 4       | Indiana Jones and the Last Crusade (1989)|\n",
    "| 5       | Speed (1994)                             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "l1K79akTebWa"
   },
   "outputs": [],
   "source": [
    "item_similarity = cosine_similarity(user_movie_matrix.T.fillna(0)) # Find the movie-movie similarity, by filling Nan as 0\n",
    "item_item_sim = pd.DataFrame(item_similarity, index=user_movie_matrix.columns, columns=user_movie_matrix.columns) # Convert into data frame\n",
    "item_item_sim.to_csv('item_item_similarity.csv', index=True) # Save movie-movie similarity as .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the movie name:  Jurassic Park (1993)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Ranking | Movie Name                                |\n",
      "|---------|-------------------------------------------|\n",
      "| 1       | Top Gun (1986)                            |\n",
      "| 2       | Speed (1994)                              |\n",
      "| 3       | Raiders of the Lost Ark (1981)            |\n",
      "| 4       | Empire Strikes Back, The (1980)           |\n",
      "| 5       | Indiana Jones and the Last Crusade (1989) |\n"
     ]
    }
   ],
   "source": [
    "# Code the function here\n",
    "movie_name = input(\"Enter the movie name: \") # Receive the movie name from the user\n",
    "num = 5\n",
    "matched_movie = movies[movies['title'].str.lower() == movie_name.lower()] # Fetch the movie_id for the inputted movie name\n",
    "\n",
    "if matched_movie.empty: # If there is not matched movie_id, it means movie_id is invalid and throw error\n",
    "    print(\"Please enter a valid movie name\")\n",
    "else: # If movie_id is valid, proceed with below\n",
    "    movie_id = matched_movie['movie_id'].values[0]  # Extract the movie ID as scalar value\n",
    "    movie_sim_score = item_item_sim[movie_id] # Get similarity scores for the selected movie\n",
    "    # Convert it into data frame with movie_id as index and values as movie_sim score\n",
    "    movie_sim_score = pd.DataFrame({\n",
    "        'movie_id': movie_sim_score.index,\n",
    "        'sim_score': movie_sim_score.values\n",
    "    })\n",
    "    #movie_sim_score.to_csv('movie_sim_score.csv', index=True) # Save sim_score of movie as .csv \n",
    "    movie_sim_score = movie_sim_score[movie_sim_score['movie_id'] != movie_id] # Remove the selected movie itself from the list\n",
    "    movie_sim_score = movie_sim_score.merge(movies[['movie_id', 'title']], on='movie_id') # Merge movie titles with movie_id for sorting\n",
    "    movie_sim_score = movie_sim_score.sort_values(by=['sim_score', 'title'], ascending=[False, True]) # Sort the similarity scores in descending order\n",
    "    top_5_titles = movie_sim_score['title'].head(num) # Get top num movies\n",
    "    # Do the below for formatting the printing\n",
    "    title_width = max(top_5_titles.apply(len).max(), len(\"Movie Name\"))\n",
    "    print(f\"| Ranking | {'Movie Name'.ljust(title_width)} |\") # Print table header\n",
    "    print(f\"|{'-' * 9}|{'-' * (title_width + 2)}|\")\n",
    "    # Print each movie with ranking\n",
    "    for rank, title in enumerate(top_5_titles, start=1):\n",
    "        print(f\"| {str(rank).ljust(7)} | {title.ljust(title_width)} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhZXLz7Rh_VC"
   },
   "source": [
    "## **Part 3: Graph-Based Recommender (Pixie-Inspired Algorithm)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_YceL18lWlN"
   },
   "source": [
    "### **Adjacency List**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFF1tUDsipIX"
   },
   "source": [
    "#### **Objective**\n",
    "In this task, you will preprocess the Movie dataset and construct a **graph representation** where:\n",
    "- **Users** are connected to the movies they have rated.\n",
    "- **Movies** are connected to users who have rated them.\n",
    "  \n",
    "This graph structure will help in exploring **user-movie relationships** for recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3OPInjhkUzy"
   },
   "source": [
    "#### **Step 1: Merge Ratings with Movie Titles**\n",
    "Since we have **movie IDs** in the ratings dataset but need human-readable movie titles, we will:\n",
    "1. Merge the `ratings` DataFrame with the `movies` DataFrame using the `'movie_id'` column.\n",
    "2. This allows each rating to be associated with a **movie title**.\n",
    "\n",
    "#### **Hint:**\n",
    "Use the following Pandas operation to merge:\n",
    "```python\n",
    "ratings = ratings.merge(movies, on='movie_id')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OPUXyNVkfHr"
   },
   "source": [
    "\n",
    "#### **Step 2: Aggregate Ratings**\n",
    "Since multiple users may rate the same movie multiple times, we:\n",
    "1. Group the dataset by `['user_id', 'movie_id', 'title']`.\n",
    "2. Compute the **mean rating** for each movie by each user.\n",
    "3. Reset the index to ensure we maintain a clean DataFrame structure.\n",
    "\n",
    "#### **Hint:**  \n",
    "Use `groupby()` and `mean()` as follows:\n",
    "```python\n",
    "ratings = ratings.groupby(['user_id', 'movie_id', 'title'])['rating'].mean().reset_index()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NU1fB66WkqEO"
   },
   "source": [
    "#### **Step 3: Normalize Ratings**\n",
    "Since different users have different rating biases, we normalize ratings by:\n",
    "1. **Computing each user's mean rating**.\n",
    "2. **Subtracting the mean rating** from each individual rating.\n",
    "\n",
    "#### **Instructions:**\n",
    "- Use `groupby('user_id')` to group ratings by users.\n",
    "- Apply `transform(lambda x: x - x.mean())` to adjust ratings.\n",
    "\n",
    "#### **Hint:**  \n",
    "Normalize ratings using:\n",
    "```python\n",
    "ratings['rating'] = ratings.groupby('user_id')['rating'].transform(lambda x: x - x.mean())\n",
    "```\n",
    "This ensures each user’s ratings are centered around zero, making similarity calculations fairer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79NB8zIWkvWP"
   },
   "source": [
    "#### **Step 4: Construct the Graph Representation**\n",
    "We represent the user-movie interactions as an **undirected graph** using an **adjacency list**:\n",
    "- Each **user** is a node connected to movies they rated.\n",
    "- Each **movie** is a node connected to users who rated it.\n",
    "\n",
    "#### **Graph Construction Steps:**\n",
    "1. Initialize an empty dictionary `graph = {}`.\n",
    "2. Iterate through the **ratings dataset**.\n",
    "3. For each `user_id` and `movie_id` pair:\n",
    "   - Add the movie to the user’s set of connections.\n",
    "   - Add the user to the movie’s set of connections.\n",
    "\n",
    "#### **Hint:**  \n",
    "The following code builds the graph:\n",
    "\n",
    "```python\n",
    "graph = {}\n",
    "for _, row in ratings.iterrows():\n",
    "    user, movie = row['user_id'], row['movie_id']\n",
    "    if user not in graph:\n",
    "        graph[user] = set()\n",
    "    if movie not in graph:\n",
    "        graph[movie] = set()\n",
    "    graph[user].add(movie)\n",
    "    graph[movie].add(user)\n",
    "```\n",
    "\n",
    "This results in a **bipartite graph**, where:\n",
    "- **Users** are connected to multiple movies.\n",
    "- **Movies** are connected to multiple users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEuVgjAAk4KV"
   },
   "source": [
    "#### **Step 5: Understanding the Graph**\n",
    "- **Nodes** in the graph represent **users and movies**.\n",
    "- **Edges** exist between a user and a movie **if the user has rated the movie**.\n",
    "- This structure allows us to find **users with similar movie tastes** and **movies frequently watched together**.\n",
    "\n",
    "#### **Exploring the Graph**\n",
    "- **Find a user’s rated movies:**  \n",
    "  ```python\n",
    "  user_id = 1\n",
    "  print(graph[user_id])  # Movies rated by user 1\n",
    "  ```\n",
    "\n",
    "- **Find users who rated a movie:**  \n",
    "  ```python\n",
    "  movie_id = 50\n",
    "  print(graph[movie_id])  # Users who rated movie 50\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "b4V2aL4DiMM4"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the user id to find the movies rated by them :  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies rated by user 1 : ['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', 'Get Shorty (1995)', 'Copycat (1995)', 'Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)', 'Twelve Monkeys (1995)', 'Babe (1995)', 'Dead Man Walking (1995)', 'Richard III (1995)', 'Seven (Se7en) (1995)', 'Usual Suspects, The (1995)', 'Mighty Aphrodite (1995)', 'Postino, Il (1994)', \"Mr. Holland's Opus (1995)\", 'French Twist (Gazon maudit) (1995)', 'From Dusk Till Dawn (1996)', 'White Balloon, The (1995)', \"Antonia's Line (1995)\", 'Angels and Insects (1995)', 'Muppet Treasure Island (1996)', 'Braveheart (1995)', 'Taxi Driver (1976)', 'Rumble in the Bronx (1995)', 'Birdcage, The (1996)', 'Brothers McMullen, The (1995)', 'Bad Boys (1995)', 'Apollo 13 (1995)', 'Batman Forever (1995)', 'Belle de jour (1967)', 'Crimson Tide (1995)', 'Crumb (1994)', 'Desperado (1995)', 'Doom Generation, The (1995)', 'Free Willy 2: The Adventure Home (1995)', 'Mad Love (1995)', 'Nadja (1994)', 'Net, The (1995)', 'Strange Days (1995)', 'To Wong Foo, Thanks for Everything! Julie Newmar (1995)', 'Billy Madison (1995)', 'Clerks (1994)', 'Disclosure (1994)', 'Dolores Claiborne (1994)', 'Eat Drink Man Woman (1994)', 'Exotica (1994)', 'Ed Wood (1994)', 'Hoop Dreams (1994)', 'I.Q. (1994)', 'Star Wars (1977)', 'Legends of the Fall (1994)', 'Madness of King George, The (1994)', 'Natural Born Killers (1994)', 'Outbreak (1995)', 'Professional, The (1994)', 'Pulp Fiction (1994)', 'Priest (1994)', 'Quiz Show (1994)', 'Three Colors: Red (1994)', 'Three Colors: Blue (1993)', 'Three Colors: White (1994)', 'Stargate (1994)', 'Santa Clause, The (1994)', 'Shawshank Redemption, The (1994)', \"What's Eating Gilbert Grape (1993)\", 'While You Were Sleeping (1995)', 'Ace Ventura: Pet Detective (1994)', 'Crow, The (1994)', 'Forrest Gump (1994)', 'Four Weddings and a Funeral (1994)', 'Lion King, The (1994)', 'Mask, The (1994)', 'Maverick (1994)', 'Faster Pussycat! Kill! Kill! (1965)', 'Brother Minister: The Assassination of Malcolm X (1994)', \"Carlito's Way (1993)\", 'Firm, The (1993)', 'Free Willy (1993)', 'Fugitive, The (1993)', 'Hot Shots! Part Deux (1993)', 'Hudsucker Proxy, The (1994)', 'Jurassic Park (1993)', 'Much Ado About Nothing (1993)', \"Robert A. Heinlein's The Puppet Masters (1994)\", 'Ref, The (1994)', 'Remains of the Day, The (1993)', 'Searching for Bobby Fischer (1993)', 'Sleepless in Seattle (1993)', 'Blade Runner (1982)', 'So I Married an Axe Murderer (1993)', 'Nightmare Before Christmas, The (1993)', 'True Romance (1993)', 'Welcome to the Dollhouse (1995)', 'Home Alone (1990)', 'Aladdin (1992)', 'Terminator 2: Judgment Day (1991)', 'Dances with Wolves (1990)', 'Silence of the Lambs, The (1991)', 'Snow White and the Seven Dwarfs (1937)', 'Fargo (1996)', 'Heavy Metal (1981)', 'Aristocats, The (1970)', 'All Dogs Go to Heaven 2 (1996)', 'Theodore Rex (1995)', 'Sgt. Bilko (1996)', 'Diabolique (1996)', 'Moll Flanders (1996)', 'Kids in the Hall: Brain Candy (1996)', 'Mystery Science Theater 3000: The Movie (1996)', 'Operation Dumbo Drop (1995)', 'Truth About Cats & Dogs, The (1996)', 'Flipper (1996)', 'Horseman on the Roof, The (Hussard sur le toit, Le) (1995)', 'Wallace & Gromit: The Best of Aardman Animation (1996)', 'Haunted World of Edward D. Wood Jr., The (1995)', 'Cold Comfort Farm (1995)', 'Rock, The (1996)', 'Twister (1996)', 'Maya Lin: A Strong Clear Vision (1994)', 'Striptease (1996)', 'Independence Day (ID4) (1996)', 'Cable Guy, The (1996)', 'Frighteners, The (1996)', 'Lone Star (1996)', 'Phenomenon (1996)', 'Spitfire Grill, The (1996)', 'Godfather, The (1972)', 'Supercop (1992)', 'Bound (1996)', 'Kansas City (1996)', \"Breakfast at Tiffany's (1961)\", 'Wizard of Oz, The (1939)', 'Gone with the Wind (1939)', 'Citizen Kane (1941)', '2001: A Space Odyssey (1968)', 'Mr. Smith Goes to Washington (1939)', 'Big Night (1996)', 'D3: The Mighty Ducks (1996)', 'Love Bug, The (1969)', 'Homeward Bound: The Incredible Journey (1993)', '20,000 Leagues Under the Sea (1954)', 'Bedknobs and Broomsticks (1971)', 'Sound of Music, The (1965)', 'Die Hard (1988)', 'Lawnmower Man, The (1992)', 'Unhook the Stars (1996)', 'Long Kiss Goodnight, The (1996)', 'Ghost and the Darkness, The (1996)', 'Jude (1996)', 'Swingers (1996)', 'Willy Wonka and the Chocolate Factory (1971)', 'Sleeper (1973)', 'Fish Called Wanda, A (1988)', \"Monty Python's Life of Brian (1979)\", 'Dirty Dancing (1987)', 'Reservoir Dogs (1992)', 'Platoon (1986)', \"Weekend at Bernie's (1989)\", 'Basic Instinct (1992)', 'Glengarry Glen Ross (1992)', 'Top Gun (1986)', 'On Golden Pond (1981)', 'Return of the Pink Panther, The (1974)', 'Abyss, The (1989)', 'Jean de Florette (1986)', 'Manon of the Spring (Manon des sources) (1986)', 'Private Benjamin (1980)', 'Monty Python and the Holy Grail (1974)', 'Wrong Trousers, The (1993)', 'Cinema Paradiso (1988)', 'Delicatessen (1991)', 'Empire Strikes Back, The (1980)', 'Princess Bride, The (1987)', 'Raiders of the Lost Ark (1981)', 'Brazil (1985)', 'Aliens (1986)', 'Good, The Bad and The Ugly, The (1966)', '12 Angry Men (1957)', 'Clockwork Orange, A (1971)', 'Apocalypse Now (1979)', 'Return of the Jedi (1983)', 'GoodFellas (1990)', 'Alien (1979)', 'Army of Darkness (1993)', 'Psycho (1960)', 'Blues Brothers, The (1980)', 'Godfather: Part II, The (1974)', 'Full Metal Jacket (1987)', 'Grand Day Out, A (1992)', 'Henry V (1989)', 'Amadeus (1984)', 'Raging Bull (1980)', 'Right Stuff, The (1983)', 'Sting, The (1973)', 'Terminator, The (1984)', 'Dead Poets Society (1989)', 'Graduate, The (1967)', 'Nikita (La Femme Nikita) (1990)', 'Bridge on the River Kwai, The (1957)', 'Shining, The (1980)', 'Evil Dead II (1987)', 'Groundhog Day (1993)', 'Unforgiven (1992)', 'Back to the Future (1985)', 'Patton (1970)', 'Akira (1988)', 'Cyrano de Bergerac (1990)', 'Young Frankenstein (1974)', 'This Is Spinal Tap (1984)', 'Indiana Jones and the Last Crusade (1989)', 'M*A*S*H (1970)', 'Unbearable Lightness of Being, The (1988)', 'Room with a View, A (1986)', 'Pink Floyd - The Wall (1982)', 'Field of Dreams (1989)', 'When Harry Met Sally... (1989)', \"Bram Stoker's Dracula (1992)\", 'Cape Fear (1991)', 'Nightmare on Elm Street, A (1984)', 'Mirror Has Two Faces, The (1996)', 'Breaking the Waves (1996)', 'Star Trek: First Contact (1996)', 'Sling Blade (1996)', 'Ridicule (1996)', '101 Dalmatians (1996)', 'Die Hard 2 (1990)', 'Star Trek VI: The Undiscovered Country (1991)', 'Star Trek: The Wrath of Khan (1982)', 'Star Trek III: The Search for Spock (1984)', 'Star Trek IV: The Voyage Home (1986)', 'Batman Returns (1992)', 'Young Guns (1988)', 'Under Siege (1992)', 'Jaws (1975)', 'Mars Attacks! (1996)', 'Citizen Ruth (1996)', 'Jerry Maguire (1996)', 'Raising Arizona (1987)', 'Sneakers (1992)', 'Beavis and Butt-head Do America (1996)', 'Last of the Mohicans, The (1992)', 'Kolya (1996)', 'Jungle2Jungle (1997)', \"Smilla's Sense of Snow (1997)\", \"Devil's Own, The (1997)\", 'Chasing Amy (1997)', 'Turbo: A Power Rangers Movie (1997)', 'Grosse Pointe Blank (1997)', 'Austin Powers: International Man of Mystery (1997)', 'Fifth Element, The (1997)', 'Shall We Dance? (1996)', 'Lost World: Jurassic Park, The (1997)', 'Pillow Book, The (1995)', 'Batman & Robin (1997)', \"My Best Friend's Wedding (1997)\", 'When the Cats Away (Chacun cherche son chat) (1996)', 'Men in Black (1997)', 'Contact (1997)', 'George of the Jungle (1997)', 'Event Horizon (1997)', 'Air Bud (1997)', 'In the Company of Men (1997)', 'Steel (1997)', 'Mimic (1997)', 'Hunt for Red October, The (1990)', 'Kull the Conqueror (1997)', 'unknown', 'Full Monty, The (1997)', 'Gattaca (1997)', 'Starship Troopers (1997)', 'Good Will Hunting (1997)']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the movie id to find the users who rated :  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users who rated movie 2 : [1, 5, 13, 22, 30, 42, 49, 64, 72, 83, 87, 92, 95, 102, 110, 130, 178, 193, 197, 200, 201, 207, 213, 217, 222, 234, 249, 250, 256, 267, 268, 271, 276, 279, 280, 292, 293, 301, 303, 305, 320, 325, 327, 346, 363, 373, 374, 378, 379, 385, 387, 393, 398, 399, 405, 407, 416, 425, 429, 435, 442, 450, 455, 466, 472, 484, 487, 495, 497, 506, 521, 532, 536, 543, 551, 561, 566, 600, 618, 621, 622, 627, 632, 640, 642, 643, 648, 650, 653, 655, 660, 671, 682, 686, 705, 709, 715, 727, 738, 746, 749, 751, 757, 764, 773, 774, 790, 795, 796, 798, 804, 806, 807, 815, 826, 830, 844, 846, 864, 868, 870, 880, 886, 889, 896, 899, 916, 924, 934, 943]\n"
     ]
    }
   ],
   "source": [
    "#### Code the function here\n",
    "ratings = ratings.drop(columns=['title'], errors='ignore') # To avoid errors during execution of merge multiple times or duplication of columns.\n",
    "ratings = ratings.merge(movies[['movie_id', 'title']], on='movie_id') # Merge only 'title' from movies\n",
    "# Normalizing ratings by calculating mean rating for a movie and subtracting mean from each rating\n",
    "ratings = ratings.groupby(['user_id', 'movie_id', 'title'])['rating'].mean().reset_index()\n",
    "ratings['rating'] = ratings.groupby('user_id')['rating'].transform(lambda x: x - x.mean())\n",
    "graph = {} # Initialize adjacency list as a dictionary\n",
    "# building bi-partite graph with users as one group of nodes and movies as another group\n",
    "for _, row in ratings.iterrows(): # Loop through the ratings data frame\n",
    "    user, movie, weight = row['user_id'], row['title'], row['rating']\n",
    "    if pd.isna(weight) or weight == 0: # Skip connections with zero or missing weight\n",
    "        continue\n",
    "    if user not in graph: # If user is not already a node in the graph create node with user_id as key and initialize with an empty dictionary\n",
    "        graph[user] = {}\n",
    "    if movie not in graph: # # If movie is not already a node in the graph create node with movie_id as key and initialize with an empty dictionary\n",
    "        graph[movie] = {}\n",
    "    #Establish a bidirectional(undirected) link between movies and users if a user has rated that movie\n",
    "    # Add the movie to the user's list of neighbors, with the rating as the edge weight\n",
    "    graph[user][movie] = weight\n",
    "    # Add the user to the movie's list of neighbors, with the rating as the edge weight\n",
    "    graph[movie][user] = weight\n",
    "user_id = int(input(\"Enter the user id to find the movies rated by them : \")) # Receive the user id from tester\n",
    "print(\"Movies rated by user\", user_id, \":\", list(graph[user_id].keys())) # Print the respective movies rated by user\n",
    "movie_id = int(input(\"Enter the movie id to find the users who rated : \")) # Receive the movie_id from tester\n",
    "if movie_id < 1 or movie_id > 1682: # Check if movie_id is valid\n",
    "    print(\"Invalid movie id\")\n",
    "else:\n",
    "    movie_title_arr = movies.loc[movies['movie_id'] == movie_id, 'title'].values\n",
    "    movie_title = movie_title_arr[0]  # Extract the string from array\n",
    "    print(\"Users who rated movie\", movie_title, \":\", list(graph[movie_title].keys())) # print the users who rated the movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZE31gB7lImI"
   },
   "source": [
    "### **Implement Weighted Random Walks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHe42rlJl9kD"
   },
   "source": [
    "#### **Random Walk-Based Movie Recommendation System (Weighted Pixie)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyqptwreo-IP"
   },
   "source": [
    "#### **Objective**\n",
    "In this task, you will implement a **random-walk-based recommendation algorithm** using the **Weighted Pixie** method. This technique uses a **user-movie bipartite graph** to recommend movies by simulating a random walk from a given user or movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFgyzzdCpfzu"
   },
   "source": [
    "#### **Step 1: Import Required Libraries**\n",
    "Make sure you have the necessary libraries:\n",
    "\n",
    "```python\n",
    "import random  # For random walks\n",
    "import pandas as pd  # For handling data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FVGjhl0ppFK"
   },
   "source": [
    "#### **Step 2: Implement the Random Walk Algorithm**\n",
    "Your task is to **simulate a random walk** from a given starting point in the **bipartite user-movie graph**.\n",
    "\n",
    "##### **Hints for Implementation**\n",
    "- Start from **either a user or a movie**.\n",
    "- At each step, **randomly move** to a connected node.\n",
    "- Keep track of **how many times each movie is visited**.\n",
    "- After completing the walk, **rank movies by visit count**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7D7Pj6trss9"
   },
   "source": [
    "#### **Step 3: Implement User-Based Recommendation**\n",
    "**Hints:**\n",
    "- Check if the `user_id` exists in the `graph`.\n",
    "- Start a loop that runs for `walk_length` steps.\n",
    "- Randomly pick a **connected node** (user or movie).\n",
    "- Track how many times each **movie** is visited.\n",
    "- Sort movies by visit frequency and return the **top N**.\n",
    "\n",
    "#### **Step 4: Implement Movie-Based Recommendation**\n",
    "**Hints:**\n",
    "- Find the `movie_id` corresponding to the given `movie_name`.\n",
    "- Ensure the movie exists in the `graph`.\n",
    "- Start a random walk from that movie.\n",
    "- Follow the same **tracking and ranking** process as the user-based version.\n",
    "\n",
    "**Note:**  \n",
    "**Your task:** Implement a function `weighted_pixie_recommend(user_id, walk_length=15, num=5)` or `weighted_pixie_recommend(movie_name, walk_length=15, num=5)`.  \n",
    "**Implement either Step 3 or Step 4.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxN_ibCCrCpx"
   },
   "source": [
    "#### **Step 5: Running Your Recommendation System**\n",
    "Once your function is implemented, test it by calling:\n",
    "\n",
    "##### **Example: User-Based Recommendation**\n",
    "```python\n",
    "weighted_pixie_recommend(1, walk_length=15, num=5)\n",
    "```\n",
    "| Ranking | Movie Name                     |\n",
    "|---------|--------------------------------|\n",
    "| 1       | My Own Private Idaho (1991)   |\n",
    "| 2       | Aladdin (1992)                |\n",
    "| 3       | 12 Angry Men (1957)           |\n",
    "| 4       | Happy Gilmore (1996)          |\n",
    "| 5       | Copycat (1995)                |\n",
    "\n",
    "\n",
    "##### **Example: Movie-Based Recommendation**\n",
    "```python\n",
    "weighted_pixie_recommend(\"Jurassic Park (1993)\", walk_length=10, num=5)\n",
    "```\n",
    "| Ranking | Movie Name                           |\n",
    "|---------|-------------------------------------|\n",
    "| 1       | Rear Window (1954)                 |\n",
    "| 2       | Great Dictator, The (1940)         |\n",
    "| 3       | Field of Dreams (1989)             |\n",
    "| 4       | Casablanca (1942)                  |\n",
    "| 5       | Nightmare Before Christmas, The (1993) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpUH9IzVr5aQ"
   },
   "source": [
    "#### **Step 6: Understanding the Results**\n",
    "Your function should return a **DataFrame** structured as follows:\n",
    "\n",
    "| Ranking | Movie Name |\n",
    "|---------|-----------|\n",
    "| 1       | Movie A   |\n",
    "| 2       | Movie B   |\n",
    "| 3       | Movie C   |\n",
    "| 4       | Movie D   |\n",
    "| 5       | Movie E   |\n",
    "\n",
    "Each movie is ranked based on **how frequently it was visited** during the walk.\n",
    "\n",
    "#### **Experiment with Different Parameters**\n",
    "- Try different **`walk_length`** values and observe how it changes recommendations.\n",
    "- Adjust the number of recommended movies (`num`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "tZD5fjG-lx3b"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter user id :  1\n",
      "Enter the walk length :  12\n",
      "Enter the number of top movies to be listed :  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ranking                       Movie Name\n",
      "       1           Terminator, The (1984)\n",
      "       2                  Net, The (1995)\n",
      "       3 Shawshank Redemption, The (1994)\n",
      "       4               Stand by Me (1986)\n",
      "       5                    Gandhi (1982)\n"
     ]
    }
   ],
   "source": [
    "# Code the function here\n",
    "def weighted_choice_with_tie_break(nodes, weights):\n",
    "    \"\"\"\n",
    "    Select the node with the highest weight.\n",
    "    If there is a tie (multiple nodes with the same max weight), choose randomly among them.\n",
    "    \"\"\"\n",
    "    max_weight = max(weights) # Get the maximum weight\n",
    "    max_weight_nodes = []\n",
    "\n",
    "    for i in range(len(nodes)): # Collect all nodes with the highest weight\n",
    "        if weights[i] == max_weight:\n",
    "            max_weight_nodes.append(nodes[i])\n",
    "    return random.choice(max_weight_nodes)     # Randomly pick one among the tied nodes if there is more than one node with same maximum weights\n",
    "    \n",
    "def weighted_pixie_recommend(user_id, walk_length, graph):\n",
    "    movie_visit_count = {} # Initialize the movie_visit_count dictionary\n",
    "    current_node = user_id # initialize current_node as the user_id inputted\n",
    "\n",
    "    # Perform the random walk for the specified number of steps\n",
    "    for i in range(walk_length):\n",
    "        neighbors = list(graph[current_node].keys())  # Get neighbors (movies or users) as list\n",
    "        if not neighbors: # If no neighbors (dead end), break out of the loop\n",
    "            break\n",
    "        neighbor_weights = [graph[current_node][neighbor] for neighbor in neighbors] # Get the corresponding weights for the neighbors\n",
    "        next_node = weighted_choice_with_tie_break(neighbors, neighbor_weights) # Select the next node using weighted choice with tie-breaking\n",
    "        if isinstance(next_node, str):  # Movie nodes are strings. If the next node is a movie, increment its visit count\n",
    "            if next_node not in movie_visit_count: # Add movie to dictionary and increment\n",
    "                movie_visit_count[next_node] = 0\n",
    "            movie_visit_count[next_node] += 1    \n",
    "        current_node = next_node # Move to the next node\n",
    "    \n",
    "    return movie_visit_count\n",
    "\n",
    "user_id = int(input(\"Enter user id : \")) # Get the user_id from the user\n",
    "walk_length = int(input(\"Enter the walk length : \")) # Get the walk length\n",
    "num = int(input(\"Enter the number of top movies to be listed : \")) # Get the number of recommendations to be given\n",
    "recommended_movies = weighted_pixie_recommend(user_id, walk_length, graph) # Call the function to get the movies\n",
    "sorted_movies = sorted(recommended_movies, key=lambda k: recommended_movies[k], reverse=True) #Sort the movies in reverse order based on visit count\n",
    "# Form data frame\n",
    "top_movies = sorted_movies[:num]  # Select only top num movies\n",
    "movies_df = pd.DataFrame({\n",
    "    'Ranking': range(1, num + 1),\n",
    "    'Movie Name': top_movies\n",
    "})\n",
    "print(movies_df.to_string(index=False))  # Print without index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User-User Collaborative Filtering Accuracy:\n",
      "  RMSE: 1.0146\n",
      "  MAE : 0.8060\n"
     ]
    }
   ],
   "source": [
    "train_ratings, test_ratings = train_test_split(ratings_data, test_size=0.2, random_state=42)\n",
    "user_movie_matrix = train_ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0) #Formation of user-movie matrix\n",
    "user_similarity = cosine_similarity(user_movie_matrix) # Find similarity between users using cosine similarity\n",
    "user_user_sim = pd.DataFrame(user_similarity, index=user_movie_matrix.index, columns=user_movie_matrix.index) # Convert into 2d similarity dataframe with both rows and columns as users\n",
    "actual_ratings = []\n",
    "predicted_list = []\n",
    "for _, row in test_ratings.iterrows():\n",
    "    user_id = row[\"user_id\"]\n",
    "    movie_id = row[\"movie_id\"]\n",
    "    actual = row[\"rating\"]\n",
    "\n",
    "    if user_id in user_user_sim.index and movie_id in user_movie_matrix.columns:\n",
    "        non_zero_mask = user_movie_matrix != 0 # Create a mask where ratings are non-zero. True when rating is present and False when movie is not rated\n",
    "        similarity_row = user_user_sim.loc[user_id] # Get the row of the inputted user_id\n",
    "        similarity_row[user_id] = 0 # Exclude the user's own similarity\n",
    "        masked_similarities = non_zero_mask.mul(similarity_row, axis=0) # Keeps similarity scores only for users who rated a given movie. Zeros out the similarity if a user didn’t rate that movie.\n",
    "    # Multiply the above non_zero_mask with the user_movie matrix A matrix where each rating position is replaced by the similarity of that user, only if the user rated that movie. Otherwise, it remains 0.\n",
    "        weighted_sum = user_movie_matrix.mul(masked_similarities, axis=0).sum(axis=0)\n",
    "        sim_sum = masked_similarities.sum(axis=0) # Compute sum of similarities only for users who rated\n",
    "        predicted_ratings = (weighted_sum / sim_sum).fillna(0) # Avoid division by zero (fill NaN with 0\n",
    "        predicted_rating = predicted_ratings[movie_id]\n",
    "        actual_ratings.append(actual)\n",
    "        predicted_list.append(predicted_rating)\n",
    "# Final accuracy scores\n",
    "rmse = np.sqrt(mean_squared_error(actual_ratings, predicted_list))\n",
    "mae = mean_absolute_error(actual_ratings, predicted_list)\n",
    "\n",
    "print(f\"\\nUser-User Collaborative Filtering Accuracy:\")\n",
    "print(f\"  RMSE: {rmse:.4f}\")\n",
    "print(f\"  MAE : {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item-Item Collaborative Filtering Accuracy:\n",
      "  RMSE: 1.0128\n",
      "  MAE : 0.8067\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "train_ratings, test_ratings = train_test_split(ratings_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create user-movie matrix\n",
    "user_movie_matrix = train_ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "\n",
    "# Transpose for item-item CF\n",
    "movie_user_matrix = user_movie_matrix.T  # Now rows are movies, columns are users\n",
    "\n",
    "# Compute movie similarity\n",
    "item_similarity = cosine_similarity(movie_user_matrix)\n",
    "item_item_sim = pd.DataFrame(item_similarity, index=movie_user_matrix.index, columns=movie_user_matrix.index)\n",
    "\n",
    "actual_ratings = []\n",
    "predicted_ratings = []\n",
    "\n",
    "# Loop over test data\n",
    "for _, row in test_ratings.iterrows():\n",
    "    user_id = row[\"user_id\"]\n",
    "    movie_id = row[\"movie_id\"]\n",
    "    actual = row[\"rating\"]\n",
    "    \n",
    "    if movie_id in item_item_sim.index and user_id in user_movie_matrix.index:\n",
    "        similarity_scores = item_item_sim.loc[movie_id]  # Similarities between this movie and all others\n",
    "        similarity_scores[movie_id] = 0  # Exclude self-similarity\n",
    "\n",
    "        user_ratings = user_movie_matrix.loc[user_id]  # Ratings by this user\n",
    "        rated_movies = user_ratings[user_ratings > 0].index  # Movies the user has rated\n",
    "        \n",
    "        relevant_similarities = similarity_scores[rated_movies]\n",
    "        relevant_ratings = user_ratings[rated_movies]\n",
    "\n",
    "        if relevant_similarities.sum() > 0:\n",
    "            weighted_sum = np.dot(relevant_similarities, relevant_ratings)\n",
    "            sim_sum = relevant_similarities.sum()\n",
    "            predicted_rating = weighted_sum / sim_sum\n",
    "        else:\n",
    "            predicted_rating = user_ratings.mean()  # Fallback: use user’s average rating\n",
    "        \n",
    "        actual_ratings.append(actual)\n",
    "        predicted_ratings.append(predicted_rating)\n",
    "\n",
    "# Final accuracy scores\n",
    "rmse = np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
    "mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
    "\n",
    "print(f\"\\nItem-Item Collaborative Filtering Accuracy:\")\n",
    "print(f\"  RMSE: {rmse:.4f}\")\n",
    "print(f\"  MAE : {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Step 1: Train-test split (if not already done)\n",
    "train_ratings, test_ratings = train_test_split(ratings_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Create ground truth mapping: user_id -> set of movie_ids in test set\n",
    "test_user_movies = defaultdict(set)\n",
    "for _, row in test_ratings.iterrows():\n",
    "    test_user_movies[row['user_id']].add(row['movie_id'])\n",
    "\n",
    "# Step 3: Set parameters\n",
    "K = 10\n",
    "walk_length = 500  # Reduced for speed\n",
    "num_sample_users = 100  # Evaluate only on 100 users\n",
    "\n",
    "# Step 4: Sampling users\n",
    "test_user_list = list(test_user_movies.keys())\n",
    "random.shuffle(test_user_list)\n",
    "sample_users = test_user_list[:num_sample_users]\n",
    "\n",
    "# Step 5: Initialize metrics\n",
    "precision_total = 0\n",
    "recall_total = 0\n",
    "hit_total = 0\n",
    "evaluated_users = 0\n",
    "\n",
    "# Step 6: Evaluate Pixie algorithm\n",
    "for user_id in tqdm(sample_users, desc=\"Evaluating Pixie\"):\n",
    "    if user_id not in graph:\n",
    "        continue  # skip users not present in the graph\n",
    "\n",
    "    visit_counts = weighted_pixie_recommend(user_id, walk_length, graph)\n",
    "    recommended_movies = sorted(visit_counts, key=visit_counts.get, reverse=True)\n",
    "    top_k_recommendations = recommended_movies[:K]\n",
    "\n",
    "    ground_truth = test_user_movies[user_id]\n",
    "    if not ground_truth:\n",
    "        continue\n",
    "\n",
    "    hits = len(set(top_k_recommendations) & ground_truth)\n",
    "    precision = hits / K\n",
    "    recall = hits / len(ground_truth)\n",
    "    hit_rate = 1 if hits > 0 else 0\n",
    "\n",
    "    precision_total += precision\n",
    "    recall_total += recall\n",
    "    hit_total += hit_rate\n",
    "    evaluated_users += 1\n",
    "\n",
    "# Step 7: Final averaged scores\n",
    "if evaluated_users > 0:\n",
    "    precision_at_k = precision_total / evaluated_users\n",
    "    recall_at_k = recall_total / evaluated_users\n",
    "    hit_rate_at_k = hit_total / evaluated_users\n",
    "\n",
    "    print(f\"\\n📊 Pixie Algorithm Evaluation @K={K} (on {evaluated_users} users)\")\n",
    "    print(f\"  Precision@K: {precision_at_k:.4f}\")\n",
    "    print(f\"  Recall@K   : {recall_at_k:.4f}\")\n",
    "    print(f\"  Hit Rate@K : {hit_rate_at_k:.4f}\")\n",
    "else:\n",
    "    print(\"No valid users were evaluated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q36Y2C7PxWO0"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iKlQlvBtiGe"
   },
   "source": [
    "## **Submission Requirements:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHGGedZexPs0"
   },
   "source": [
    "To successfully complete this assignment, ensure that you submit the following:\n",
    "\n",
    "\n",
    "### **1. Jupyter Notebook Submission**\n",
    "- Submit a **fully completed Jupyter Notebook** that includes:\n",
    "  - **All implemented recommendation functions** (user-based, item-based, and random walk-based recommendations).\n",
    "  - **Code explanations** in markdown cells to describe each step.\n",
    "  - **Results and insights** from running your recommendation models.\n",
    "\n",
    "\n",
    "### **2. Explanation of Pixie-Inspired Algorithms (3-5 Paragraphs)**\n",
    "- Write a **detailed explanation** of **Pixie-inspired random walk algorithms** used for recommendations.\n",
    "- Your explanation should cover:\n",
    "  - What **Pixie-inspired recommendation systems** are.\n",
    "  - How **random walks** help in identifying relevant recommendations.\n",
    "  - Any real-world applications of such algorithms in industry.\n",
    "\n",
    "\n",
    "### **3. Report for the Submitted Notebook**\n",
    "Your report should be structured as follows:\n",
    "\n",
    "#### **Title: Movie Recommendation System Report**\n",
    "\n",
    "#### **1. Introduction**\n",
    "- Briefly introduce **movie recommendation systems** and why they are important.\n",
    "- Explain the **different approaches used** (user-based, item-based, random-walk).\n",
    "\n",
    "#### **2. Dataset Description**\n",
    "- Describe the **MovieLens 100K dataset**:\n",
    "  - Number of users, movies, and ratings.\n",
    "  - What features were used.\n",
    "  - Any preprocessing performed.\n",
    "\n",
    "#### **3. Methodology**\n",
    "- Explain the three recommendation techniques implemented:\n",
    "  - **User-based collaborative filtering** (how user similarity was calculated).\n",
    "  - **Item-based collaborative filtering** (how item similarity was determined).\n",
    "  - **Random-walk-based Pixie algorithm** (why graph-based approaches are effective).\n",
    "  \n",
    "#### **4. Implementation Details**\n",
    "- Discuss the steps taken to build the functions.\n",
    "- Describe how the **adjacency list graph** was created.\n",
    "- Explain how **random walks** were performed and how visited movies were ranked.\n",
    "\n",
    "#### **5. Results and Evaluation**\n",
    "- Present **example outputs** from each recommendation approach.\n",
    "- Compare the different methods in terms of accuracy and usefulness.\n",
    "- Discuss any **limitations** in the implementation.\n",
    "\n",
    "#### **6. Conclusion**\n",
    "- Summarize the key takeaways from the project.\n",
    "- Discuss potential improvements (e.g., **hybrid models, additional features**).\n",
    "- Suggest real-world applications of the methods used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWgT_Shy-vUK"
   },
   "source": [
    "### **Submission Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nuz1s-Vh_L55"
   },
   "source": [
    "- Submit `.zip` file consisting of Jupyter Notebook and all the datafiles (provided) and the ones saved [i.e. `users.csv`, `movies.csv` and `ratings.csv`]. Also, include the Report and Pixie Algorithm explanation document.\n",
    "- [`Bonus 10 Points`] **Upload your Jupyter Notebook, Explanation Document, and Report** to your GitHub repository.\n",
    "- Ensure the repository is public and contains:\n",
    "  - `users.csv`, `movies.csv` and `ratings.csv` [These are the Dataframes which were created in part 1. Save and export them as a `.csv` file]\n",
    "  - `Movie_Recommendation.ipynb`\n",
    "  - `Pixie_Algorithm_Explanation.pdf` or `.md`\n",
    "  - `Recommendation_Report.pdf` or `.md`\n",
    "- **Submit the GitHub repository link in the cell below.**\n",
    "\n",
    "\n",
    "#### **Example Submission Format**\n",
    "```text\n",
    "GitHub Repository: https://github.com/username/Movie-Recommendation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jol9nRDau6fZ"
   },
   "outputs": [],
   "source": [
    "# Submit the Github Link here:\n",
    "https://github.com/gowshiksaravanan19/KDD-6162"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQ6aluK-0ZMa"
   },
   "source": [
    "### **Grading Rubric: ITCS 6162 - Data Mining Assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNAfeIzA_fCq"
   },
   "source": [
    "\n",
    "| **Category**                              | **Criteria**                                                     | **Points** |\n",
    "|-------------------------------------------|----------------------------------------------------------------|------------|\n",
    "| **Part 1: Exploring and Cleaning Data (15 pts)**  | Properly loads `u.user`, `u.movies`, and `u.item` datasets into DataFrames | 5 |\n",
    "|                                           | Handles missing values, duplicates, and inconsistencies appropriately | 5 |\n",
    "|                                           | Saves the cleaned datasets into CSV files: `users.csv`, `movies.csv`, `ratings.csv` | 5 |\n",
    "| **Part 2: Collaborative Filtering-Based Recommendation (30 pts)** | Implements user-based collaborative filtering correctly | 10 |\n",
    "|                                           | Implements item-based collaborative filtering correctly | 10 |\n",
    "|                                           | Computes similarity measures accurately and provides valid recommendations | 10 |\n",
    "| **Part 3: Graph-Based Recommender (Pixie-Inspired Algorithm) (35 pts)** | Constructs adjacency lists properly from user-movie interactions | 10 |\n",
    "|                                           | Implements weighted random walk-based recommendation correctly | 15 |\n",
    "|                                           | Explains and justifies the algorithm design choices (Pixie-inspired) | 10 |\n",
    "| **Code Quality & Documentation (10 pts)** | Code is well-structured, efficient, and follows best practices | 5 |\n",
    "|                                           | Markdown explanations and comments are clear and enhance understanding | 5 |\n",
    "| **Results & Interpretation (5 pts)**      | Provides meaningful insights from the recommendation system's output | 5 |\n",
    "| **Submission & Report (5 pts)**          | Submits all required files in the correct format (ZIP file with Jupyter notebook, processed CSV files, and project report) | 5 |\n",
    "| **Total**                                 |                              | 100 |\n",
    "\n",
    "#### **Bonus (10 pts)**\n",
    "| **Category**                              | **Criteria**                                                     | **Points** |\n",
    "|-------------------------------------------|----------------------------------------------------------------|------------|\n",
    "| **GitHub Submission**                     | Provides a well-documented GitHub repository with CSV files, a structured README, and a properly formatted Jupyter Notebook | 10 |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "NjxACjUgFwsk",
    "AyeSaLpRGYuC",
    "fOXp00QSbtHk",
    "MIN3XqC0eUAu",
    "u_YceL18lWlN",
    "_ZE31gB7lImI",
    "Nuz1s-Vh_L55"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
